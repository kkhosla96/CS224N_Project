IntroductionVirtually every task performed by living organisms requires energy. Energy is needed to perform heavy labor and exercise,but humans also use a great deal of energy while thinking, and even during sleep. In fact, the living cells of every organismconstantly use energy. Nutrients and other molecules are imported, metabolized (broken down) and possibly synthesizedinto new molecules, modified if needed, transported around the cell, and may be distributed to the entire organism. Forexample, the large proteins that make up muscles are actively built from smaller molecules. Complex carbohydrates arebroken down into simple sugars that the cell uses for energy. Just as energy is required to both build and demolish a building,energy is required for both the synthesis and breakdown of molecules. Additionally, signaling molecules such as hormonesand neurotransmitters are transported between cells. Pathogenic bacteria and viruses are ingested and broken down by cells.Cells must also export waste and toxins to stay healthy, and many cells must swim or move surrounding materials via thebeating motion of cellular appendages like cilia and flagella.The cellular processes listed above require a steady supply of energy. From where, and in what form, does this energycome? How do living cells obtain energy, and how do they use it? This chapter will discuss different forms of energy andthe physical laws that govern energy transfer. This chapter will also describe how cells use energy and replenish it, and howchemical reactions in the cell are performed with great efficiency.
Scientists use the term bioenergetics to discuss the concept of energy flow (Figure 6.2) through living systems, such ascells. Cellular processes such as the building and breaking down of complex molecules occur through stepwise chemicalreactions. Some of these chemical reactions are spontaneous and release energy, whereas others require energy to proceed.Just as living things must continually consume food to replenish what has been used, cells must continually produce moreenergy to replenish that used by the many energy-requiring chemical reactions that constantly take place. All of the chemicalreactions that take place inside cells, including those that use energy and those that release energy, are the cell’s metabolism.
Most life forms on earth get their energy from the sun. Plants use photosynthesis to capture sunlight, andherbivores eat those plants to obtain energy. Carnivores eat the herbivores, and decomposers digest plant and animalmatter.
During the chemical reactions of photosynthesis, energy is provided in the form of a very high-energy molecule called ATP,or adenosine triphosphate, which is the primary energy currency of all cells. Just as the dollar is used as currency to buygoods, cells use molecules of ATP as energy currency to perform immediate work. The sugar (glucose) is stored as starchor glycogen. Energy-storing polymers like these are broken down into glucose to supply molecules of ATP.Solar energy is required to synthesize a molecule of glucose during the reactions of photosynthesis. In photosynthesis, lightenergy from the sun is initially transformed into chemical energy that is temporally stored in the energy carrier moleculesATP and NADPH (nicotinamide adenine dinucleotide phosphate). The stored energy in ATP and NADPH is then usedlater in photosynthesis to build one molecule of glucose from six molecules of CO2. This process is analogous to eatingbreakfast in the morning to acquire energy for your body that can be used later in the day. Under ideal conditions, energyfrom 18 molecules of ATP is required to synthesize one molecule of glucose during the reactions of photosynthesis. Glucosemolecules can also be combined with and converted into other types of sugars. When sugars are consumed, molecules ofglucose eventually make their way into each living cell of the organism. Inside the cell, each sugar molecule is broken downthrough a complex series of chemical reactions. The goal of these reactions is to harvest the energy stored inside the sugarmolecules. The harvested energy is used to make high-energy ATP molecules, which can be used to perform work, poweringmany chemical reactions in the cell. The amount of energy needed to make one molecule of glucose from six molecules ofcarbon dioxide is 18 molecules of ATP and 12 molecules of NADPH (each one of which is energetically equivalent to threemolecules of ATP), or a total of 54 molecule equivalents required for the synthesis of one molecule of glucose. This processis a fundamental and efficient way for cells to generate the molecular energy that they require.
Plants, like this oak tree and acorn, use energy from sunlight to make sugar and other organic molecules.Both plants and animals (like this squirrel) use cellular respiration to derive energy from the organic molecules originallyproduced by plants.
Metabolic PathwaysThe processes of making and breaking down sugar molecules illustrate two types of metabolic pathways. A metabolicpathway is a series of interconnected biochemical reactions that convert a substrate molecule or molecules, step-by-step,through a series of metabolic intermediates, eventually yielding a final product or products. In the case of sugar metabolism,the first metabolic pathway synthesized sugar from smaller molecules, and the other pathway broke sugar down into smallermolecules. These two opposite processes—the first requiring energy and the second producing energy—are referred toas anabolic (building) and catabolic (breaking down) pathways, respectively. Consequently, metabolism is composed ofbuilding (anabolism) and degradation (catabolism).
There is more to the complexity of metabolism than understanding the metabolic pathways alone. Metaboliccomplexity varies from organism to organism. Photosynthesis is the primary pathway in whichphotosynthetic organisms like plants (the majority of global synthesis is done by planktonic algae) harvestthe sun’s energy and convert it into carbohydrates. The by-product of photosynthesis is oxygen, requiredby some cells to carry out cellular respiration. During cellular respiration, oxygen aids in the catabolicbreakdown of carbon compounds, like carbohydrates. Among the products of this catabolism are CO2 andATP. In addition, some eukaryotes perform catabolic processes without oxygen (fermentation); that is, theyperform or use anaerobic metabolism.Organisms probably evolved anaerobic metabolism to survive (living organisms came into existence about3.8 billion years ago, when the atmosphere lacked oxygen). Despite the differences between organismsand the complexity of metabolism, researchers have found that all branches of life share some of thesame metabolic pathways, suggesting that all organisms evolved from the same ancient common ancestor(Figure 6.4). Evidence indicates that over time, the pathways diverged, adding specialized enzymes toallow organisms to better adapt to their environment, thus increasing their chance to survive. However, theunderlying principle remains that all organisms must harvest energy from their environment and convert itto ATP to carry out cellular functions.
Anabolic and Catabolic PathwaysAnabolic pathways require an input of energy to synthesize complex molecules from simpler ones. Synthesizing sugar fromCO2 is one example. Other examples are the synthesis of large proteins from amino acid building blocks, and the synthesisof new DNA strands from nucleic acid building blocks. These biosynthetic processes are critical to the life of the cell, takeplace constantly, and demand energy provided by ATP and other high-energy molecules like NADH (nicotinamide adeninedinucleotide) and NADPH (Figure 6.5).ATP is an important molecule for cells to have in sufficient supply at all times. The breakdown of sugars illustrates how asingle molecule of glucose can store enough energy to make a great deal of ATP, 36 to 38 molecules. This is a catabolicpathway. Catabolic pathways involve the degradation (or breakdown) of complex molecules into simpler ones. Molecularenergy stored in the bonds of complex molecules is released in catabolic pathways and harvested in such a way that it can beused to produce ATP. Other energy-storing molecules, such as fats, are also broken down through similar catabolic reactionsto release energy and make ATP (Figure 6.5).It is important to know that the chemical reactions of metabolic pathways don’t take place spontaneously. Each reactionstep is facilitated, or catalyzed, by a protein called an enzyme. Enzymes are important for catalyzing all types of biologicalreactions—those that require energy as well as those that release energy.
Anabolic pathways are those that require energy to synthesize larger molecules. Catabolic pathways arethose that generate energy by breaking down larger molecules. Both types of pathways are required for maintainingthe cell’s energy balance.
Energy is defined as the ability to do work. As you’ve learned, energy exists in different forms. For example, electricalenergy, light energy, and heat energy are all different types of energy. While these are all familiar types of energy that onecan see or feel, there is another type of energy that is much less tangible. This energy is associated with something as simpleas an object held above the ground. In order to appreciate the way energy flows into and out of biological systems, it isimportant to understand more about the different types of energy that exist in the physical world.Types of EnergyWhen an object is in motion, there is energy associated with that object. In the example of an airplane in flight, there is agreat deal of energy associated with the motion of the airplane. This is because moving objects are capable of enacting achange, or doing work. Think of a wrecking ball. Even a slow-moving wrecking ball can do a great deal of damage to otherobjects. However, a wrecking ball that is not in motion is incapable of performing work. Energy associated with objects inmotion is called kinetic energy. A speeding bullet, a walking person, the rapid movement of molecules in the air (whichproduces heat), and electromagnetic radiation like light all have kinetic energy.Now what if that same motionless wrecking ball is lifted two stories above a car with a crane? If the suspended wreckingball is unmoving, is there energy associated with it? The answer is yes. The suspended wrecking ball has energy associatedwith it that is fundamentally different from the kinetic energy of objects in motion. This form of energy results from thefact that there is the potential for the wrecking ball to do work. If it is released, indeed it would do work. Because this typeof energy refers to the potential to do work, it is called potential energy. Objects transfer their energy between kinetic andpotential in the following way: As the wrecking ball hangs motionless, it has 0 kinetic and 100 percent potential energy.Once it is released, its kinetic energy begins to increase because it builds speed due to gravity. At the same time, as it nearsthe ground, it loses potential energy. Somewhere mid-fall it has 50 percent kinetic and 50 percent potential energy. Justbefore it hits the ground, the ball has nearly lost its potential energy and has near-maximal kinetic energy. Other examples ofpotential energy include the energy of water held behind a dam (Figure 6.6), or a person about to skydive out of an airplane.
Water behind a dam has potential energy. Moving water, such as in a waterfall or a rapidly flowing river, haskinetic energy.
Potential energy is not only associated with the location of matter (such as a child sitting on a tree branch), but also with thestructure of matter. A spring on the ground has potential energy if it is compressed; so does a rubber band that is pulled taut.The very existence of living cells relies heavily on structural potential energy. On a chemical level, the bonds that hold theatoms of molecules together have potential energy. Remember that anabolic cellular pathways require energy to synthesizecomplex molecules from simpler ones, and catabolic pathways release energy when complex molecules are broken down.The fact that energy can be released by the breakdown of certain chemical bonds implies that those bonds have potentialenergy. In fact, there is potential energy stored within the bonds of all the food molecules we eat, which is eventuallyharnessed for use. This is because these bonds can release energy when broken. The type of potential energy that existswithin chemical bonds, and is released when those bonds are broken, is called chemical energy (Figure 6.7). Chemicalenergy is responsible for providing living cells with energy from food. The release of energy is brought about by breakingthe molecular bonds within fuel molecules.
The molecules in gasoline (octane, the chemical formula shown) contain chemical energy within thechemical bonds. This energy is transformed into kinetic energy that allows a car to race on a racetrack.
Free EnergyAfter learning that chemical reactions release energy when energy-storing bonds are broken, an important next questionis how is the energy associated with chemical reactions quantified and expressed? How can the energy released fromone reaction be compared to that of another reaction? A measurement of free energy is used to quantitate these energytransfers. Free energy is called Gibbs free energy (abbreviated with the letter G) after Josiah Willard Gibbs, the scientistwho developed the measurement. Recall that according to the second law of thermodynamics, all energy transfers involvethe loss of some amount of energy in an unusable form such as heat, resulting in entropy. Gibbs free energy specificallyrefers to the energy associated with a chemical reaction that is available after entropy is accounted for. In other words, Gibbsfree energy is usable energy, or energy that is available to do work.Every chemical reaction involves a change in free energy, called delta G (ΔG). The change in free energy can be calculatedfor any system that undergoes such a change, such as a chemical reaction. To calculate ΔG, subtract the amount of energylost to entropy (denoted as ΔS) from the total energy change of the system. This total energy change in the system is calledenthalpy and is denoted as ΔH . The formula for calculating ΔG is as follows, where the symbol T refers to absolutetemperature in Kelvin (degrees Celsius + 273):ΔG = ΔH − TΔSThe standard free energy change of a chemical reaction is expressed as an amount of energy per mole of the reaction product(either in kilojoules or kilocalories, kJ/mol or kcal/mol; 1 kJ = 0.239 kcal) under standard pH, temperature, and pressureconditions. Standard pH, temperature, and pressure conditions are generally calculated at pH 7.0 in biological systems,25 degrees Celsius, and 100 kilopascals (1 atm pressure), respectively. It is important to note that cellular conditions varyconsiderably from these standard conditions, and so standard calculated ΔG values for biological reactions will be differentinside the cell.Endergonic Reactions and Exergonic ReactionsIf energy is released during a chemical reaction, then the resulting value from the above equation will be a negative number.In other words, reactions that release energy have a ΔG < 0. A negative ΔG also means that the products of the reactionhave less free energy than the reactants, because they gave off some free energy during the reaction. Reactions that have anegative ΔG and consequently release free energy are called exergonic reactions. Think: exergonic means energy is exitingthe system. These reactions are also referred to as spontaneous reactions, because they can occur without the addition ofenergy into the system. Understanding which chemical reactions are spontaneous and release free energy is extremely usefulfor biologists, because these reactions can be harnessed to perform work inside the cell. An important distinction must bedrawn between the term spontaneous and the idea of a chemical reaction that occurs immediately. Contrary to the everydayuse of the term, a spontaneous reaction is not one that suddenly or quickly occurs. The rusting of iron is an example of aspontaneous reaction that occurs slowly, little by little, over time.If a chemical reaction requires an input of energy rather than releasing energy, then the ΔG for that reaction will be apositive value. In this case, the products have more free energy than the reactants. Thus, the products of these reactions canbe thought of as energy-storing molecules. These chemical reactions are called endergonic reactions, and they are nonspontaneous.An endergonic reaction will not take place on its own without the addition of free energy.Let’s revisit the example of the synthesis and breakdown of the food molecule, glucose. Remember that the building ofcomplex molecules, such as sugars, from simpler ones is an anabolic process and requires energy. Therefore, the chemicalreactions involved in anabolic processes are endergonic reactions. On the other hand, the catabolic process of breakingsugar down into simpler molecules releases energy in a series of exergonic reactions. Like the example of rust above, thebreakdown of sugar involves spontaneous reactions, but these reactions don’t occur instantaneously. Figure 6.8 shows some other examples of endergonic and exergonic reactions. Later sections will provide more information about what else isrequired to make even spontaneous reactions happen more efficiently.
An important concept in the study of metabolism and energy is that of chemical equilibrium. Most chemical reactions arereversible. They can proceed in both directions, releasing energy into their environment in one direction, and absorbingit from the environment in the other direction (Figure 6.9). The same is true for the chemical reactions involved in cellmetabolism, such as the breaking down and building up of proteins into and from individual amino acids, respectively.Reactants within a closed system will undergo chemical reactions in both directions until a state of equilibrium is reached.This state of equilibrium is one of the lowest possible free energy and a state of maximal entropy. Energy must be putinto the system to push the reactants and products away from a state of equilibrium. Either reactants or products mustbe added, removed, or changed. If a cell were a closed system, its chemical reactions would reach equilibrium, and itwould die because there would be insufficient free energy left to perform the work needed to maintain life. In a livingcell, chemical reactions are constantly moving towards equilibrium, but never reach it. This is because a living cell is anopen system. Materials pass in and out, the cell recycles the products of certain chemical reactions into other reactions, andchemical equilibrium is never reached. In this way, living organisms are in a constant energy-requiring, uphill battle againstequilibrium and entropy. This constant supply of energy ultimately comes from sunlight, which is used to produce nutrientsin the process of photosynthesis.
Exergonic and endergonic reactions result in changes in Gibbs free energy. Exergonic reactions releaseenergy; endergonic reactions require energy to proceed.Activation EnergyThere is another important concept that must be considered regarding endergonic and exergonic reactions. Even exergonicreactions require a small amount of energy input to get going before they can proceed with their energy-releasing steps.These reactions have a net release of energy, but still require some energy in the beginning. This small amount of energyinput necessary for all chemical reactions to occur is called the activation energy (or free energy of activation) and isabbreviated EA (Figure 6.10).Why would an energy-releasing, negative ΔG reaction actually require some energy to proceed? The reason lies in thesteps that take place during a chemical reaction. During chemical reactions, certain chemical bonds are broken and newones are formed. For example, when a glucose molecule is broken down, bonds between the carbon atoms of the moleculeare broken. Since these are energy-storing bonds, they release energy when broken. However, to get them into a state thatallows the bonds to break, the molecule must be somewhat contorted. A small energy input is required to achieve thiscontorted state. This contorted state is called the transition state, and it is a high-energy, unstable state. For this reason,reactant molecules don’t last long in their transition state, but very quickly proceed to the next steps of the chemical reaction.Free energy diagrams illustrate the energy profiles for a given reaction. Whether the reaction is exergonic or endergonicdetermines whether the products in the diagram will exist at a lower or higher energy state than both the reactants and theproducts. However, regardless of this measure, the transition state of the reaction exists at a higher energy state than thereactants, and thus, EA is always positive.
Where does the activation energy required by chemical reactants come from? The source of the activation energy neededto push reactions forward is typically heat energy from the surroundings. Heat energy (the total bond energy of reactantsor products in a chemical reaction) speeds up the motion of molecules, increasing the frequency and force with which theycollide; it also moves atoms and bonds within the molecule slightly, helping them reach their transition state. For this reason,heating up a system will cause chemical reactants within that system to react more frequently. Increasing the pressure on asystem has the same effect. Once reactants have absorbed enough heat energy from their surroundings to reach the transitionstate, the reaction will proceed.The activation energy of a particular reaction determines the rate at which it will proceed. The higher the activation energy,the slower the chemical reaction will be. The example of iron rusting illustrates an inherently slow reaction. This reactionoccurs slowly over time because of its high EA. Additionally, the burning of many fuels, which is strongly exergonic, willtake place at a negligible rate unless their activation energy is overcome by sufficient heat from a spark. Once they begin to burn, however, the chemical reactions release enough heat to continue the burning process, supplying the activation energyfor surrounding fuel molecules. Like these reactions outside of cells, the activation energy for most cellular reactions istoo high for heat energy to overcome at efficient rates. In other words, in order for important cellular reactions to occurat appreciable rates (number of reactions per unit time), their activation energies must be lowered (Figure 6.10); this isreferred to as catalysis. This is a very good thing as far as living cells are concerned. Important macromolecules, suchas proteins, DNA, and RNA, store considerable energy, and their breakdown is exergonic. If cellular temperatures aloneprovided enough heat energy for these exergonic reactions to overcome their activation barriers, the essential componentsof a cell would disintegrate.
Thermodynamics refers to the study of energy and energy transfer involving physical matter. The matter and itsenvironment relevant to a particular case of energy transfer are classified as a system, and everything outside of that systemis called the surroundings. For instance, when heating a pot of water on the stove, the system includes the stove, the pot, andthe water. Energy is transferred within the system (between the stove, pot, and water). There are two types of systems: openand closed. An open system is one in which energy can be transferred between the system and its surroundings. The stovetopsystem is open because heat can be lost into the air. A closed system is one that cannot transfer energy to its surroundings.Biological organisms are open systems. Energy is exchanged between them and their surroundings, as they consume energystoringmolecules and release energy to the environment by doing work. Like all things in the physical world, energy issubject to the laws of physics. The laws of thermodynamics govern the transfer of energy in and among all systems in theuniverse.
The First Law of ThermodynamicsThe first law of thermodynamics deals with the total amount of energy in the universe. It states that this total amountof energy is constant. In other words, there has always been, and always will be, exactly the same amount of energyin the universe. Energy exists in many different forms. According to the first law of thermodynamics, energy may betransferred from place to place or transformed into different forms, but it cannot be created or destroyed. The transfers andtransformations of energy take place around us all the time. Light bulbs transform electrical energy into light energy. Gasstoves transform chemical energy from natural gas into heat energy. Plants perform one of the most biologically usefulenergy transformations on earth: that of converting the energy of sunlight into the chemical energy stored within organicmolecules (Figure 6.2). Some examples of energy transformations are shown in Figure 6.11.The challenge for all living organisms is to obtain energy from their surroundings in forms that they can transfer ortransform into usable energy to do work. Living cells have evolved to meet this challenge very well. Chemical energy storedwithin organic molecules such as sugars and fats is transformed through a series of cellular chemical reactions into energywithin molecules of ATP. Energy in ATP molecules is easily accessible to do work. Examples of the types of work that cellsneed to do include building complex molecules, transporting materials, powering the beating motion of cilia or flagella,contracting muscle fibers to create movement, and reproduction.
Shown are two examples of energy being transferred from one system to another and transformed fromone form to another. Humans can convert the chemical energy in food, like this ice cream cone, into kinetic energy(the energy of movement to ride a bicycle). Plants can convert electromagnetic radiation (light energy) from the suninto chemical energy.
The Second Law of ThermodynamicsA living cell’s primary tasks of obtaining, transforming, and using energy to do work may seem simple. However,the second law of thermodynamics explains why these tasks are harder than they appear. None of the energy transferswe’ve discussed, along with all energy transfers and transformations in the universe, is completely efficient. In everyenergy transfer, some amount of energy is lost in a form that is unusable. In most cases, this form is heat energy.Thermodynamically, heat energy is defined as the energy transferred from one system to another that is not doing work.For example, when an airplane flies through the air, some of the energy of the flying plane is lost as heat energy due tofriction with the surrounding air. This friction actually heats the air by temporarily increasing the speed of air molecules.
Likewise, some energy is lost as heat energy during cellular metabolic reactions. This is good for warm-blooded creatureslike us, because heat energy helps to maintain our body temperature. Strictly speaking, no energy transfer is completelyefficient, because some energy is lost in an unusable form.An important concept in physical systems is that of order and disorder (also known as randomness). The more energy thatis lost by a system to its surroundings, the less ordered and more random the system is. Scientists refer to the measure ofrandomness or disorder within a system as entropy. High entropy means high disorder and low energy (Figure 6.12). Tobetter understand entropy, think of a student’s bedroom. If no energy or work were put into it, the room would quicklybecome messy. It would exist in a very disordered state, one of high entropy. Energy must be put into the system, in the formof the student doing work and putting everything away, in order to bring the room back to a state of cleanliness and order.This state is one of low entropy. Similarly, a car or house must be constantly maintained with work in order to keep it in anordered state. Left alone, the entropy of the house or car gradually increases through rust and degradation. Molecules andchemical reactions have varying amounts of entropy as well. For example, as chemical reactions reach a state of equilibrium,entropy increases, and as molecules at a high concentration in one place diffuse and spread out, entropy also increases.
All physical systems can be thought of in this way: Living things are highly ordered, requiring constant energy input tobe maintained in a state of low entropy. As living systems take in energy-storing molecules and transform them throughchemical reactions, they lose some amount of usable energy in the process, because no reaction is completely efficient. Theyalso produce waste and by-products that aren’t useful energy sources. This process increases the entropy of the system’ssurroundings. Since all energy transfers result in the loss of some usable energy, the second law of thermodynamics statesthat every energy transfer or transformation increases the entropy of the universe. Even though living things are highlyordered and maintain a state of low entropy, the entropy of the universe in total is constantly increasing due to the loss ofusable energy with each energy transfer that occurs. Essentially, living things are in a continuous uphill battle against thisconstant increase in universal entropy.
Entropy is a measure of randomness or disorder in a system. Gases have higher entropy than liquids, andliquids have higher entropy than solids.
Even exergonic, energy-releasing reactions require a small amount of activation energy in order to proceed. However,consider endergonic reactions, which require much more energy input, because their products have more free energy thantheir reactants. Within the cell, where does energy to power such reactions come from? The answer lies with an energysupplyingmolecule called adenosine triphosphate, or ATP. ATP is a small, relatively simple molecule (Figure 6.13), butwithin some of its bonds, it contains the potential for a quick burst of energy that can be harnessed to perform cellular work.This molecule can be thought of as the primary energy currency of cells in much the same way that money is the currencythat people exchange for things they need. ATP is used to power the majority of energy-requiring cellular reactions.
ATP is the primary energy currency of the cell. It has an adenosine backbone with three phosphate groupsattached.As its name suggests, adenosine triphosphate is comprised of adenosine bound to three phosphate groups (Figure 6.13).Adenosine is a nucleoside consisting of the nitrogenous base adenine and a five-carbon sugar, ribose. The three phosphategroups, in order of closest to furthest from the ribose sugar, are labeled alpha, beta, and gamma. Together, these chemicalgroups constitute an energy powerhouse. However, not all bonds within this molecule exist in a particularly high-energystate. Both bonds that link the phosphates are equally high-energy bonds ( phosphoanhydride bonds) that, when broken, release sufficient energy to power a variety of cellular reactions and processes. These high-energy bonds are the bondsbetween the second and third (or beta and gamma) phosphate groups and between the first and second phosphate groups.The reason that these bonds are considered “high-energy” is because the products of such bond breaking—adenosinediphosphate (ADP) and one inorganic phosphate group (Pi)—have considerably lower free energy than the reactants: ATPand a water molecule. Because this reaction takes place with the use of a water molecule, it is considered a hydrolysisreaction. In other words, ATP is hydrolyzed into ADP in the following reaction:ATP + H2O → ADP + Pi + free energyLike most chemical reactions, the hydrolysis of ATP to ADP is reversible. The reverse reaction regenerates ATP from ADP+ Pi. Indeed, cells rely on the regeneration of ATP just as people rely on the regeneration of spent money through some sortof income. Since ATP hydrolysis releases energy, ATP regeneration must require an input of free energy. The formation ofATP is expressed in this equation:ADP + Pi + free energy → ATP + H2OTwo prominent questions remain with regard to the use of ATP as an energy source. Exactly how much free energy isreleased with the hydrolysis of ATP, and how is that free energy used to do cellular work? The calculated ΔG for thehydrolysis of one mole of ATP into ADP and Pi is −7.3 kcal/mole (−30.5 kJ/mol). Since this calculation is true understandard conditions, it would be expected that a different value exists under cellular conditions. In fact, the ΔG for thehydrolysis of one mole of ATP in a living cell is almost double the value at standard conditions: 14 kcal/mol (−57 kJ/mol).ATP is a highly unstable molecule. Unless quickly used to perform work, ATP spontaneously dissociates into ADP + Pi, andthe free energy released during this process is lost as heat. The second question posed above, that is, how the energy releasedby ATP hydrolysis is used to perform work inside the cell, depends on a strategy called energy coupling. Cells couple theexergonic reaction of ATP hydrolysis with endergonic reactions, allowing them to proceed. One example of energy couplingusing ATP involves a transmembrane ion pump that is extremely important for cellular function. This sodium-potassiumpump (Na+/K+ pump) drives sodium out of the cell and potassium into the cell (Figure 6.14). A large percentage of a cell’sATP is spent powering this pump, because cellular processes bring a great deal of sodium into the cell and potassium outof the cell. The pump works constantly to stabilize cellular concentrations of sodium and potassium. In order for the pumpto turn one cycle (exporting three Na+ ions and importing two K+ ions), one molecule of ATP must be hydrolyzed. WhenATP is hydrolyzed, its gamma phosphate doesn’t simply float away, but is actually transferred onto the pump protein. Thisprocess of a phosphate group binding to a molecule is called phosphorylation. As with most cases of ATP hydrolysis, aphosphate from ATP is transferred onto another molecule. In a phosphorylated state, the Na+/K+ pump has more free energyand is triggered to undergo a conformational change. This change allows it to release Na+ to the outside of the cell. Itthen binds extracellular K+, which, through another conformational change, causes the phosphate to detach from the pump.This release of phosphate triggers the K+ to be released to the inside of the cell. Essentially, the energy released from thehydrolysis of ATP is coupled with the energy required to power the pump and transport Na+ and K+ ions. ATP performscellular work using this basic form of energy coupling through phosphorylation.
Often during cellular metabolic reactions, such as the synthesis and breakdown of nutrients, certain molecules mustbe altered slightly in their conformation to become substrates for the next step in the reaction series. One example isduring the very first steps of cellular respiration, when a molecule of the sugar glucose is broken down in the processof glycolysis. In the first step of this process, ATP is required for the phosphorylation of glucose, creating a high-energybut unstable intermediate. This phosphorylation reaction powers a conformational change that allows the phosphorylatedglucose molecule to be converted to the phosphorylated sugar fructose. Fructose is a necessary intermediate for glycolysis tomove forward. Here, the exergonic reaction of ATP hydrolysis is coupled with the endergonic reaction of converting glucoseinto a phosphorylated intermediate in the pathway. Once again, the energy released by breaking a phosphate bond withinATP was used for the phosphorylation of another molecule, creating an unstable intermediate and powering an importantconformational change.
A substance that helps a chemical reaction to occur is a catalyst, and the special molecules that catalyze biochemicalreactions are called enzymes. Almost all enzymes are proteins, made up of chains of amino acids, and they perform thecritical task of lowering the activation energies of chemical reactions inside the cell. Enzymes do this by binding to thereactant molecules, and holding them in such a way as to make the chemical bond-breaking and bond-forming processestake place more readily. It is important to remember that enzymes don’t change the ΔG of a reaction. In other words, theydon’t change whether a reaction is exergonic (spontaneous) or endergonic. This is because they don’t change the free energyof the reactants or products. They only reduce the activation energy required to reach the transition state.
Enzyme Active Site and Substrate SpecificityThe chemical reactants to which an enzyme binds are the enzyme’s substrates. There may be one or more substrates,depending on the particular chemical reaction. In some reactions, a single-reactant substrate is broken down into multipleproducts. In others, two substrates may come together to create one larger molecule. Two reactants might also enter areaction, both become modified, and leave the reaction as two products. The location within the enzyme where the substratebinds is called the enzyme’s active site. The active site is where the “action” happens, so to speak. Since enzymes areproteins, there is a unique combination of amino acid residues (also called side chains, or R groups) within the active site.Each residue is characterized by different properties. Residues can be large or small, weakly acidic or basic, hydrophilic orhydrophobic, positively or negatively charged, or neutral. The unique combination of amino acid residues, their positions,sequences, structures, and properties, creates a very specific chemical environment within the active site. This specificenvironment is suited to bind, albeit briefly, to a specific chemical substrate (or substrates). Due to this jigsaw puzzle-likematch between an enzyme and its substrates (which adapts to find the best fit between the transition state and the activesite), enzymes are known for their specificity. The “best fit” results from the shape and the amino acid functional group’sattraction to the substrate. There is a specifically matched enzyme for each substrate and, thus, for each chemical reaction;however, there is flexibility as well.The fact that active sites are so perfectly suited to provide specific environmental conditions also means that they are subjectto influences by the local environment. It is true that increasing the environmental temperature generally increases reactionrates, enzyme-catalyzed or otherwise. However, increasing or decreasing the temperature outside of an optimal range canaffect chemical bonds within the active site in such a way that they are less well suited to bind substrates. High temperatureswill eventually cause enzymes, like other biological molecules, to denature, a process that changes the natural properties of a substance. Likewise, the pH of the local environment can also affect enzyme function. Active site amino acid residueshave their own acidic or basic properties that are optimal for catalysis. These residues are sensitive to changes in pH thatcan impair the way substrate molecules bind. Enzymes are suited to function best within a certain pH range, and, as withtemperature, extreme pH values (acidic or basic) of the environment can cause enzymes to denature.Induced Fit and Enzyme FunctionFor many years, scientists thought that enzyme-substrate binding took place in a simple “lock-and-key” fashion. This modelasserted that the enzyme and substrate fit together perfectly in one instantaneous step. However, current research supportsa more refined view called induced fit (Figure 6.16). The induced-fit model expands upon the lock-and-key model bydescribing a more dynamic interaction between enzyme and substrate. As the enzyme and substrate come together, theirinteraction causes a mild shift in the enzyme’s structure that confirms an ideal binding arrangement between the enzymeand the transition state of the substrate. This ideal binding maximizes the enzyme’s ability to catalyze its reaction.
When an enzyme binds its substrate, an enzyme-substrate complex is formed. This complex lowers the activation energyof the reaction and promotes its rapid progression in one of many ways. On a basic level, enzymes promote chemicalreactions that involve more than one substrate by bringing the substrates together in an optimal orientation. The appropriateregion (atoms and bonds) of one molecule is juxtaposed to the appropriate region of the other molecule with which it mustreact. Another way in which enzymes promote the reaction of their substrates is by creating an optimal environment withinthe active site for the reaction to occur. Certain chemical reactions might proceed best in a slightly acidic or non-polarenvironment. The chemical properties that emerge from the particular arrangement of amino acid residues within an activesite create the perfect environment for an enzyme’s specific substrates to react.You’ve learned that the activation energy required for many reactions includes the energy involved in manipulating orslightly contorting chemical bonds so that they can easily break and allow others to reform. Enzymatic action can aid thisprocess. The enzyme-substrate complex can lower the activation energy by contorting substrate molecules in such a wayas to facilitate bond-breaking, helping to reach the transition state. Finally, enzymes can also lower activation energies bytaking part in the chemical reaction itself. The amino acid residues can provide certain ions or chemical groups that actuallyform covalent bonds with substrate molecules as a necessary step of the reaction process. In these cases, it is important toremember that the enzyme will always return to its original state at the completion of the reaction. One of the hallmarkproperties of enzymes is that they remain ultimately unchanged by the reactions they catalyze. After an enzyme is donecatalyzing a reaction, it releases its product(s).
According to the induced-fit model, both enzyme and substrate undergo dynamic conformational changesupon binding. The enzyme contorts the substrate into its transition state, thereby increasing the rate of the reaction.
Control of Metabolism Through Enzyme RegulationIt would seem ideal to have a scenario in which all of the enzymes encoded in an organism’s genome existed in abundantsupply and functioned optimally under all cellular conditions, in all cells, at all times. In reality, this is far from the case.A variety of mechanisms ensure that this does not happen. Cellular needs and conditions vary from cell to cell, and changewithin individual cells over time. The required enzymes and energetic demands of stomach cells are different from thoseof fat storage cells, skin cells, blood cells, and nerve cells. Furthermore, a digestive cell works much harder to process andbreak down nutrients during the time that closely follows a meal compared with many hours after a meal. As these cellulardemands and conditions vary, so do the amounts and functionality of different enzymes.Since the rates of biochemical reactions are controlled by activation energy, and enzymes lower and determine activationenergies for chemical reactions, the relative amounts and functioning of the variety of enzymes within a cell ultimatelydetermine which reactions will proceed and at which rates. This determination is tightly controlled. In certain cellularenvironments, enzyme activity is partly controlled by environmental factors, like pH and temperature. There are othermechanisms through which cells control the activity of enzymes and determine the rates at which various biochemicalreactions will occur.Regulation of Enzymes by MoleculesEnzymes can be regulated in ways that either promote or reduce their activity. There are many different kinds of moleculesthat inhibit or promote enzyme function, and various mechanisms exist for doing so. In some cases of enzyme inhibition,for example, an inhibitor molecule is similar enough to a substrate that it can bind to the active site and simply block thesubstrate from binding. When this happens, the enzyme is inhibited through competitive inhibition, because an inhibitormolecule competes with the substrate for active site binding (Figure 6.17). On the other hand, in noncompetitive inhibition,an inhibitor molecule binds to the enzyme in a location other than an allosteric site and still manages to block substratebinding to the active site.
Competitive and noncompetitive inhibition affect the rate of reaction differently. Competitive inhibitorsaffect the initial rate but do not affect the maximal rate, whereas noncompetitive inhibitors affect the maximal rate.Some inhibitor molecules bind to enzymes in a location where their binding induces a conformational change that reducesthe affinity of the enzyme for its substrate. This type of inhibition is called allosteric inhibition (Figure 6.18). Mostallosterically regulated enzymes are made up of more than one polypeptide, meaning that they have more than one proteinsubunit. When an allosteric inhibitor binds to an enzyme, all active sites on the protein subunits are changed slightly suchthat they bind their substrates with less efficiency. There are allosteric activators as well as inhibitors. Allosteric activatorsbind to locations on an enzyme away from the active site, inducing a conformational change that increases the affinity ofthe enzyme’s active site(s) for its substrate(s).
Allosteric inhibitors modify the active site of the enzyme so that substrate binding is reduced or prevented.In contrast, allosteric activators modify the active site of the enzyme so that the affinity for the substrate increases.
Many enzymes don’t work optimally, or even at all, unless bound to other specific non-protein helper molecules, eithertemporarily through ionic or hydrogen bonds or permanently through stronger covalent bonds. Two types of helpermolecules are cofactors and coenzymes. Binding to these molecules promotes optimal conformation and function for theirrespective enzymes. Cofactors are inorganic ions such as iron (Fe++) and magnesium (Mg++). One example of an enzymethat requires a metal ion as a cofactor is the enzyme that builds DNA molecules, DNA polymerase, which requires boundzinc ion (Zn++) to function. Coenzymes are organic helper molecules, with a basic atomic structure made up of carbon andhydrogen, which are required for enzyme action. The most common sources of coenzymes are dietary vitamins (Figure6.20). Some vitamins are precursors to coenzymes and others act directly as coenzymes. Vitamin C is a coenzyme formultiple enzymes that take part in building the important connective tissue component, collagen. An important step in thebreakdown of glucose to yield energy is catalysis by a multi-enzyme complex called pyruvate dehydrogenase. Pyruvatedehydrogenase is a complex of several enzymes that actually requires one cofactor (a magnesium ion) and five differentorganic coenzymes to catalyze its specific chemical reaction. Therefore, enzyme function is, in part, regulated by anabundance of various cofactors and coenzymes, which are supplied primarily by the diets of most organisms.
Vitamins are important coenzymes or precursors of coenzymes, and are required for enzymes to functionproperly. Multivitamin capsules usually contain mixtures of all the vitamins at different percentages.
Enzyme CompartmentalizationIn eukaryotic cells, molecules such as enzymes are usually compartmentalized into different organelles. This allows for yetanother level of regulation of enzyme activity. Enzymes required only for certain cellular processes can be housed separatelyalong with their substrates, allowing for more efficient chemical reactions. Examples of this sort of enzyme regulationbased on location and proximity include the enzymes involved in the latter stages of cellular respiration, which take placeexclusively in the mitochondria, and the enzymes involved in the digestion of cellular debris and foreign materials, locatedwithin lysosomes.Feedback Inhibition in Metabolic PathwaysMolecules can regulate enzyme function in many ways. A major question remains, however: What are these moleculesand where do they come from? Some are cofactors and coenzymes, ions, and organic molecules, as you’ve learned. Whatother molecules in the cell provide enzymatic regulation, such as allosteric modulation, and competitive and noncompetitiveinhibition? The answer is that a wide variety of molecules can perform these roles. Some of these molecules includepharmaceutical and non-pharmaceutical drugs, toxins, and poisons from the environment. Perhaps the most relevant sourcesof enzyme regulatory molecules, with respect to cellular metabolism, are the products of the cellular metabolic reactionsthemselves. In a most efficient and elegant way, cells have evolved to use the products of their own reactions for feedbackinhibition of enzyme activity. Feedback inhibition involves the use of a reaction product to regulate its own furtherproduction (Figure 6.21). The cell responds to the abundance of specific products by slowing down production duringanabolic or catabolic reactions. Such reaction products may inhibit the enzymes that catalyzed their production through themechanisms described above.
Metabolic pathways are a series of reactions catalyzed by multiple enzymes. Feedback inhibition, wherethe end product of the pathway inhibits an upstream step, is an important regulatory mechanism in cells.The production of both amino acids and nucleotides is controlled through feedback inhibition. Additionally, ATP is anallosteric regulator of some of the enzymes involved in the catabolic breakdown of sugar, the process that produces ATP.In this way, when ATP is abundant, the cell can prevent its further production. Remember that ATP is an unstable moleculethat can spontaneously dissociate into ADP. If too much ATP were present in a cell, much of it would go to waste. On theother hand, ADP serves as a positive allosteric regulator (an allosteric activator) for some of the same enzymes that areinhibited by ATP. Thus, when relative levels of ADP are high compared to ATP, the cell is triggered to produce more ATPthrough the catabolism of sugar.